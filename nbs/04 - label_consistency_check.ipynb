{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVERVIEW\n",
    "\n",
    "One of the unique rules of this competition is a special requirement regarding the label hierarchy consistency. We predict nine exam-level and one image-level label, where some of the labels are conflicting and must adhere to a specific hirearchy displayed on the image below.\n",
    "\n",
    "![hierarchy](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F115173%2Fa2a5ee66b5799274141dd547cc3ea466%2FPE%20figure.jpg?generation=1599575183749576&alt=media)\n",
    "\n",
    "According to the data description page: \n",
    "\n",
    "> Winning submissions will be inspected to ensure label predictions adhere to the expected label hierarchy defined by the diagram on the Data page. The metric intends to heavily penalize submissions which mis-predict in this manner, however due to the complexity of predictions at both image and study levels and as an extra precaution, the host will verify that prospective winners have not made conflicting label predictions. The requirements which submissions will be held to are [specified by the host in this post](https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection/discussion/183473).\n",
    "\n",
    "The goal of this notebook is to develop a code that checks for label consistency in a submission file to make sure it adheres to the competition rules. Please note that the code has not been fully verified with the organizers yet and can be interpreting some of the rules incorrectly. I will be happy to correct any inconsistencies you might find if you point me to them in the comments section :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERSION HISTORY\n",
    "\n",
    "- v1: first version of the notebook\n",
    "- v2: corrected handling of `prediction == 0.5` for some labels as noted by [@anthracene](https://www.kaggle.com/anthracene) in the comments\n",
    "- v3: wrapped consistency checks into `check_consitency()` function\n",
    "- v4: text adjustments (no code changes)\n",
    "- v5: added rule 1d (see the discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKING CONSISTENCY\n",
    "\n",
    "## PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "train = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/train.csv')\n",
    "test  = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import one of the public kernel submission files to check it for the label consistency requirements. As an example, I am using the `submission.csv` file produced by [@seraphwedd18](https://www.kaggle.com/seraphwedd18) in [this kernel](https://www.kaggle.com/seraphwedd18/pe-detection-with-keras-model-creation/output?scriptVersionId=42782514&select=submission.csv). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# IMPORT EXAMPLE SUBMISSION\n",
    "sub = pd.read_csv('../input/pe-detection-with-keras-model-creation/submission.csv')\n",
    "sub.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FORMALIZING CONSISTENCY RULES\n",
    "\n",
    "The rules below represent my understanding of the label consistency requirements outlined by [@anthracene](https://www.kaggle.com/anthracene) in [this discussion topic](https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection/discussion/183473). I encourage you to read the topic before inspecting the rules below.\n",
    "\n",
    "We implement the following two groups of rules on the exam level. The first group specifies conflicting characteristics of PE if it is detected on any of the images in the exam. The second group makes sure that if there are no images with detected PE in the exam, we do not predict any of the PE charactersitcs to be present.\n",
    "\n",
    "1. If there is at least one image per `StudyInstanceUID` with `pe_present_on_image` > 0.5, then:\n",
    "    - either `rv_lv_ratio_lt_1` or `rv_lv_ratio_gte_1` must have p > 0.5; both cannot have p > 0.5.\n",
    "    - at least one of `central_pe`, `rightsided_pe` and `leftsided_pe` must have p > 0.5; multiple having p > 0.5 is allowed.\n",
    "    - `acute_and_chronic_pe` and `chronic_pe`: only one of them can have p > 0.5; neither having p > 0.5 is allowed.\n",
    "2. If there are no images per `StudyInstanceUID` with `pe_present_on_image` > 0.5, then:\n",
    "    - either `indeterminate` or `negative_exam_for_pe` must have p > 0.5; both cannot have p > 0.5.\n",
    "    - all positive-related labels: `rv_lv_ratio_lt_1`, `rv_lv_ratio_gte_1`, `central_pe`, `rightsided_pe`, `leftsided_pe`, `acute_and_chronic_pe` and `chronic_pe` must have p < 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECKING CONSISTENCY RULES\n",
    "\n",
    "Let's start by checking if there is at least one image predicted as positive (`pe_present_on_image > 0.5`) in an exam and splitting our submission data into positive and negative exams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check label consistency rules separately for positive and negative exams. We will identify rows that do not satisfy any of the requirements and merge them into a data frame representing the inconsistent predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the submission file has 26081 rows that do not satisfy the rule labeled as 2b. This means that, although the exam does not have any images with predicted PE (i.e., p(`pe_present_on_image`) > 0.5), some of the positive-related labels describing the characteristics of PE have p > 0.5. In my understanding, these inconsistencies should be fixed in order not to be disqualified from the leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRAPPING IN A FUNCTION\n",
    "\n",
    "The function below wraps the previous code blocks into a function that can be applied to a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_consistency(sub, test):\n",
    "    \n",
    "    '''\n",
    "    Checks label consistency and returns the errors\n",
    "    \n",
    "    Args:\n",
    "    sub   = submission dataframe (pandas)\n",
    "    test  = test.csv dataframe (pandas)\n",
    "    '''\n",
    "    \n",
    "    # EXAM LEVEL\n",
    "    for i in test['StudyInstanceUID'].unique():\n",
    "        df_tmp = sub.loc[sub.id.str.contains(i, regex = False)].reset_index(drop = True)\n",
    "        df_tmp['StudyInstanceUID'] = df_tmp['id'].str.split('_').str[0]\n",
    "        df_tmp['label_type']       = df_tmp['id'].str.split('_').str[1:].apply(lambda x: '_'.join(x))\n",
    "        del df_tmp['id']\n",
    "        if i == test['StudyInstanceUID'].unique()[0]:\n",
    "            df = df_tmp.copy()\n",
    "        else:\n",
    "            df = pd.concat([df, df_tmp], axis = 0)\n",
    "    df_exam = df.pivot(index = 'StudyInstanceUID', columns = 'label_type', values = 'label')\n",
    "    \n",
    "    # IMAGE LEVEL\n",
    "    df_image = sub.loc[sub.id.isin(test.SOPInstanceUID)].reset_index(drop = True)\n",
    "    df_image = df_image.merge(test, how = 'left', left_on = 'id', right_on = 'SOPInstanceUID')\n",
    "    df_image.rename(columns = {\"label\": \"pe_present_on_image\"}, inplace = True)\n",
    "    del df_image['id']\n",
    "    \n",
    "    # MERGER\n",
    "    df = df_exam.merge(df_image, how = 'left', on = 'StudyInstanceUID')\n",
    "    ids    = ['StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID']\n",
    "    labels = [c for c in df.columns if c not in ids]\n",
    "    df = df[ids + labels]\n",
    "    \n",
    "    # SPLIT NEGATIVE AND POSITIVE EXAMS\n",
    "    df['positive_images_in_exam'] = df['StudyInstanceUID'].map(df.groupby(['StudyInstanceUID']).pe_present_on_image.max())\n",
    "    df_pos = df.loc[df.positive_images_in_exam >  0.5]\n",
    "    df_neg = df.loc[df.positive_images_in_exam <= 0.5]\n",
    "    \n",
    "    # CHECKING CONSISTENCY OF POSITIVE EXAM LABELS\n",
    "    rule1a = df_pos.loc[((df_pos.rv_lv_ratio_lt_1  >  0.5)  & \n",
    "                         (df_pos.rv_lv_ratio_gte_1 >  0.5)) | \n",
    "                        ((df_pos.rv_lv_ratio_lt_1  <= 0.5)  & \n",
    "                         (df_pos.rv_lv_ratio_gte_1 <= 0.5))].reset_index(drop = True)\n",
    "    rule1a['broken_rule'] = '1a'\n",
    "    rule1b = df_pos.loc[(df_pos.central_pe    <= 0.5) & \n",
    "                        (df_pos.rightsided_pe <= 0.5) & \n",
    "                        (df_pos.leftsided_pe  <= 0.5)].reset_index(drop = True)\n",
    "    rule1b['broken_rule'] = '1b'\n",
    "    rule1c = df_pos.loc[(df_pos.acute_and_chronic_pe > 0.5) & \n",
    "                        (df_pos.chronic_pe           > 0.5)].reset_index(drop = True)\n",
    "    rule1c['broken_rule'] = '1c'\n",
    "    rule1d = df_pos.loc[(df_pos.indeterminate        > 0.5) | \n",
    "                        (df_pos.negative_exam_for_pe > 0.5)].reset_index(drop = True)\n",
    "    rule1d['broken_rule'] = '1d'\n",
    "\n",
    "    \n",
    "    # CHECKING CONSISTENCY OF NEGATIVE EXAM LABELS\n",
    "    rule2a = df_neg.loc[((df_neg.indeterminate        >  0.5)  & \n",
    "                         (df_neg.negative_exam_for_pe >  0.5)) | \n",
    "                        ((df_neg.indeterminate        <= 0.5)  & \n",
    "                         (df_neg.negative_exam_for_pe <= 0.5))].reset_index(drop = True)\n",
    "    rule2a['broken_rule'] = '2a'\n",
    "    rule2b = df_neg.loc[(df_neg.rv_lv_ratio_lt_1     > 0.5) | \n",
    "                        (df_neg.rv_lv_ratio_gte_1    > 0.5) |\n",
    "                        (df_neg.central_pe           > 0.5) | \n",
    "                        (df_neg.rightsided_pe        > 0.5) | \n",
    "                        (df_neg.leftsided_pe         > 0.5) |\n",
    "                        (df_neg.acute_and_chronic_pe > 0.5) | \n",
    "                        (df_neg.chronic_pe           > 0.5)].reset_index(drop = True)\n",
    "    rule2b['broken_rule'] = '2b'\n",
    "    \n",
    "    # MERGING INCONSISTENT PREDICTIONS\n",
    "    errors = pd.concat([rule1a, rule1b, rule1c, rule1d, rule2a, rule2b], axis = 0)\n",
    "    \n",
    "    # OUTPUT\n",
    "    print('Found', len(errors), 'inconsistent predictions')\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "errors = check_consistency(sub, test)\n",
    "errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
