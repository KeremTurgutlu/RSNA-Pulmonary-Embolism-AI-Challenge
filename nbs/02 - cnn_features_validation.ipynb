{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path(\"../rsna_data/\")\n",
    "train_df = pd.read_csv(datapath/'train.csv')\n",
    "train_df.pe_present_on_image.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load All Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdatapath = (datapath/'full_raw_512')\n",
    "files = get_image_files(imgdatapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesdict = defaultdict(list)\n",
    "for o in files: filesdict[o.parent.name] += [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filesdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = dict(zip(train_df['SOPInstanceUID'], train_df['pe_present_on_image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files), len(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(o): return labels_dict[o.stem.split(\"_\")[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = datapath/'metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_files = get_files(metadata_path, extensions='.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid2metadata = {o.stem:pd.read_csv(o) for o in metadata_files}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Fold PIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 512\n",
    "# resize = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cv = True\n",
    "FOLD = 0\n",
    "\n",
    "if do_cv: \n",
    "    cv_pids_dir = (datapath/'cv_pids')\n",
    "    if not cv_pids_dir.exists(): cv_pids_dir.mkdir()\n",
    "    cv_df = train_df[['StudyInstanceUID', 'negative_exam_for_pe']].drop_duplicates().reset_index(drop=True)\n",
    "    all_pids = cv_df['StudyInstanceUID'].values\n",
    "    valid_pids = pd.read_pickle(datapath/f'cv_pids/pids_fold{FOLD}.pkl')\n",
    "    train_pids = list(set(all_pids).difference(valid_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_pids), len(valid_pids), len(train_pids+valid_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadf = pd.concat([pid2metadata[o] for o in train_pids]).reset_index(drop=True)\n",
    "valid_metadf = pd.concat([pid2metadata[o]  for o in valid_pids]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Valid Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files,valid_files = [],[]\n",
    "for o in train_pids: train_files += filesdict[o]\n",
    "for o in valid_pids: valid_files += filesdict[o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_files), len(valid_files), len(train_files+valid_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(f\"./models/xresnet34-{resize}-PR-fold{FOLD}-export.pkl\", cpu=False)\n",
    "learn = load_learner(f\"./models/effb3-{resize}-PR-fold{FOLD}-export.pkl\", cpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get preds & Visual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingHook:\n",
    "    def __init__(self, m, savedir, filename, csz=500000):\n",
    "        store_attr(\"m,savedir,filename,csz\")\n",
    "        \n",
    "        if len(m._forward_hooks) > 0: self.reset()\n",
    "        \n",
    "        self.embeddings = tensor([])\n",
    "        self.hook = Hook(m, self.hook_fn, cpu=True)\n",
    "        self.save_iter = 0   \n",
    "        \n",
    "        savedir = Path(savedir)\n",
    "        if not savedir.exists(): savedir.mkdir()\n",
    "    \n",
    "    def hook_fn(self, m, inp, out): \n",
    "        \"Stack and save computed embeddings\"\n",
    "        self.embeddings = torch.cat([self.embeddings, out])\n",
    "        if self.embeddings.shape[0] > self.csz:\n",
    "            self.save()\n",
    "            self.embeddings = tensor([])\n",
    "    \n",
    "    def reset(self): self.m._forward_hooks = OrderedDict()\n",
    "        \n",
    "    def save(self): \n",
    "        torch.save(self.embeddings, self.savedir/f\"{self.filename}_part{self.save_iter}.pth\")\n",
    "        self.save_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_files), len(valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = train_files + valid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dl = learn.dls.test_dl(all_files, with_labels=True, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f\"full_EFFNETB3_{resize}_ALL_FROM_FOLD{FOLD}\"; folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embhook = EmbeddingHook(learn.model[1][1], datapath/f'cnn_embs/{folder}', 'xresnet34_embeddings')\n",
    "embhook = EmbeddingHook(learn.model._avg_pooling, datapath/f'cnn_embs/{folder}', 'effb3_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs = learn.get_preds(dl=all_dl, act=noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save preds, embeddings and ordered valid filenames\n",
    "# torch.save(embhook.embeddings,  datapath/f'cnn_embs/{folder}'/'xresnet34_embeddings_finalpart.pth')\n",
    "# torch.save(preds,  datapath/f'cnn_embs/{folder}'/'preds.pth')\n",
    "# torch.save(all_dl.dataset.items,  datapath/f'cnn_embs/{folder}'/'files.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preds, embeddings and ordered valid filenames\n",
    "torch.save(embhook.embeddings,  datapath/f'cnn_embs/{folder}'/'effb3_embeddings_finalpart.pth')\n",
    "torch.save(preds,  datapath/f'cnn_embs/{folder}'/'preds.pth')\n",
    "torch.save(all_dl.dataset.items,  datapath/f'cnn_embs/{folder}'/'files.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = torch.cat([torch.load(o) for o in [o for o in (datapath/f'cnn_embs/{folder}').ls() if 'embeddings' in str(o)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.shape, preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qi = proportion of positive images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Weighted Log Loss (Competition Metric) - 2D CNN models\n",
    "\n",
    "sz 256\n",
    "\n",
    "Xresnet34 Fold 0, sz=256, temp=1.3, 0.3881 / Effnetb3 Fold 0, sz=256 temp=1.2 0.3356\n",
    "\n",
    "Xresnet34 Fold 1, sz=256, temp = 1.3, 0.3684\n",
    "\n",
    "sz 512\n",
    "\n",
    "Xresnet34 Fold 0, sz=512, temp =0.8 0.2639 / Effnetb3 Fold 0, sz=512, temp=1.5 0.2655\n",
    "\n",
    "Xresnet34 Fold 1, sz=512, temp = 1.5, 0.2679\n",
    "\n",
    "Xresnet34 Fold 2 sz=512, temp = 1.4, 0.2686\n",
    "\n",
    "Xresnet34 Fold 3 sz=512, temp = 1.1, 0.2373\n",
    "\n",
    "Xresnet34 Fold 4 sz=512, temp = 1.1, 0.2533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = L(valid_files).map(get_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_p = np.mean(valid_labels)\n",
    "1-valid_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids = L(valid_files).map(lambda o: o.parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid2qi =dict(pd.DataFrame({\"sid\":sids, \"labels\": valid_labels}).groupby(\"sid\")['labels'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qis = tensor([sid2qi[o] for o in sids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp in np.linspace(0.1, 2, 20):\n",
    "    l = F.cross_entropy(preds.float()/temp, targs, reduction='none')\n",
    "    avg_logloss = (l*qis).sum()/qis.sum()\n",
    "    print(temp, avg_logloss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qis.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((preds.float()/.8).softmax(1)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_losses = F.cross_entropy(preds.float()/0.8, targs, reduction='none')\n",
    "tot_img_loss = (img_losses*qis).sum()\n",
    "tot_img_wgts = qis.sum()\n",
    "avg_logloss = tot_img_loss/tot_img_wgts;avg_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_img_loss, tot_img_wgts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exam Weighted Log Loss\n",
    "\n",
    "**Mean baseline**\n",
    "\n",
    "Fold 1 0.3518\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_targets = L([\n",
    "#           'positive_exam_for_pe'\n",
    "            'negative_exam_for_pe',\n",
    "            'indeterminate',\n",
    "\n",
    "            'rv_lv_ratio_gte_1',\n",
    "            'rv_lv_ratio_lt_1',\n",
    "    # none\n",
    "\n",
    "            'leftsided_pe',\n",
    "            'rightsided_pe',\n",
    "            'central_pe',\n",
    "\n",
    "            'chronic_pe',\n",
    "            'acute_and_chronic_pe',           \n",
    "            # neither chronic or acute_and_chronic\n",
    "          \n",
    "    \n",
    "    \n",
    "#             'qa_motion',\n",
    "#             'qa_contrast',\n",
    "#             'flow_artifact',\n",
    "#             'true_filling_defect_not_pe',\n",
    "             ]); exam_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pe_wgt = 0.0736196319\n",
    "indeterminate_wgt = 0.09202453988\n",
    "\n",
    "rv_lv_gte_1_wgt = 0.2346625767\n",
    "rv_lv_lt_1_wgt = 0.0782208589\n",
    "\n",
    "left_pe_wgt = 0.06257668712\n",
    "right_pe_wgt = 0.06257668712\n",
    "central_pe_wgt = 0.1877300613\n",
    "\n",
    "chronic_wgt = 0.1042944785\n",
    "acute_chronic_wgt = 0.1042944785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_wgts = tensor([0.0736196319,0.09202453988,0.2346625767,0.0782208589,0.06257668712,0.06257668712,0.1877300613,0.1042944785, 0.1042944785])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targsdf = train_df[train_df.StudyInstanceUID.isin(train_pids)][[\"StudyInstanceUID\"]+exam_targets].drop_duplicates()\n",
    "valid_targsdf = train_df[train_df.StudyInstanceUID.isin(valid_pids)][[\"StudyInstanceUID\"]+exam_targets].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_mean_preds = dict(train_targsdf[exam_targets].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_mean_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_losses = F.binary_cross_entropy(tensor(list(exam_mean_preds.values()))[None,...].repeat(len(valid_pids),1),\n",
    "                                     tensor(valid_targsdf[exam_targets].values).float(), \n",
    "                                     reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_exam_loss = (exam_losses*exam_wgts).sum()\n",
    "tot_exam_wgts = (len(valid_pids)*exam_wgts.sum())\n",
    "avg_exam_loss = tot_exam_loss/tot_exam_wgts; avg_exam_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine both\n",
    "\n",
    "Almost equal weights just take mean of two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_wgt = 0.07361963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tot_img_loss*img_wgt + tot_exam_loss) / (tot_img_wgts*img_wgt + tot_exam_wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
