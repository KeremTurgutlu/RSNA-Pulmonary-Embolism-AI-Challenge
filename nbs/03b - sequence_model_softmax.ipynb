{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path(\"../rsna_data/\")\n",
    "embspath = Path(datapath/\"cnn_embs\")\n",
    "train_df = pd.read_csv(datapath/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(embspath.ls())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings & Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 4\n",
    "folddir = embspath/f'full_512_ALL_FROM_FOLD{fold}'; list(folddir.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.cat([torch.load(folddir/f\"xresnet34_embeddings_{o}.pth\") for o in [\"part0\", \"part1\", \"part2\", \"finalpart\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.load(folddir/\"preds.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = torch.load(folddir/\"files.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape, preds.shape, len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add zero for padded input idx\n",
    "input_pad_idx = len(embeddings)\n",
    "embeddings = torch.cat([embeddings, torch.zeros_like(embeddings[:1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[input_pad_idx], embeddings.shape, input_pad_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = datapath/'metadata'\n",
    "metadata_files = get_files(metadata_path, extensions=\".csv\")\n",
    "metadf = pd.concat([pd.read_csv(o) for o in metadata_files]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metadf['StudyInstanceUID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scaler(o): return (o - min(o))/(max(o) - min(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_pos = metadf.groupby('StudyInstanceUID')['ImagePositionPatient2'].apply(minmax_scaler)\n",
    "metadf.loc[:,'scaled_position'] = scaled_pos.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_feat_cols = ['scaled_position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(metadf[meta_feat_cols]).sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std = metadf[meta_feat_cols].agg(['mean', 'std']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_dict = dict(zip(mean_std.index, mean_std.values.tolist())); mean_std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaler for training\n",
    "for c in mean_std_dict: metadf[c] = (metadf[c] - mean_std_dict[c][0]) / mean_std_dict[c][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_feats_dict = dict(zip(metadf['SOPInstanceUID'], metadf[meta_feat_cols].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meta_feats_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_embeddings = []\n",
    "for o in files:\n",
    "    sopid = o.stem.split(\"_\")[1]\n",
    "    meta_embeddings.append(meta_feats_dict[sopid])\n",
    "meta_embeddings = np.vstack(meta_embeddings)\n",
    "meta_embeddings= tensor(meta_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_preds = True\n",
    "if use_preds:\n",
    "    meta_embeddings = torch.cat([meta_embeddings, preds[:,1].view(-1,1).float()],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_embeddings.shape, type(meta_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_embeddings = torch.cat([meta_embeddings, torch.zeros_like(meta_embeddings[:1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape, meta_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_embeddings = torch.cat([embeddings, meta_embeddings], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         # positive, negative, indeterminate\n",
    "#         self.pe_head = nn.Linear(dim//4, 3) # softmax\n",
    "#         # rv / lv >=,  < 1 or neither\n",
    "#         self.rv_lv_head = nn.Linear(dim//4, 3) # softmax\n",
    "#         # l,r,c pe\n",
    "#         self.pe_position_head = nn.Linear(dim//4, 3) # sigmoid\n",
    "#         # chronic, ac-chr or neither\n",
    "#         self.chronic_pe_head = nn.Linear(dim//4, 3) # softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_targets = L(['pe_present_on_image'])\n",
    "exam_targets = L([\n",
    "#           'positive_exam_for_pe'\n",
    "            'negative_exam_for_pe',\n",
    "            'indeterminate',\n",
    "\n",
    "            'rv_lv_ratio_gte_1',\n",
    "            'rv_lv_ratio_lt_1',\n",
    "    # none\n",
    "\n",
    "            'leftsided_pe',\n",
    "            'rightsided_pe',\n",
    "            'central_pe',\n",
    "\n",
    "            'chronic_pe',\n",
    "            'acute_and_chronic_pe',           \n",
    "            # neither chronic or acute_and_chronic\n",
    "          \n",
    "    \n",
    "    \n",
    "#             'qa_motion',\n",
    "#             'qa_contrast',\n",
    "#             'flow_artifact',\n",
    "#             'true_filling_defect_not_pe',\n",
    "             ]); exam_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = train_df[['StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID']+image_targets+exam_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_dict = dict(zip(targets_df['SOPInstanceUID'].values, targets_df[image_targets+exam_targets].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(targets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict = defaultdict(list)\n",
    "for i,o in enumerate(files):\n",
    "    slice_no, sopid = o.stem.split(\"_\")\n",
    "    sid = o.parent.name\n",
    "    slice_no = int(slice_no)        \n",
    "    files_dict[sid].append({\"slice_no\":slice_no, \"embs_idx\":i, \"img_y\":targets_dict[sopid][0], \"exam_y\":targets_dict[sopid][1:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pids = list(files_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_arr = list(files_dict[all_pids[0]][0]['exam_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(pid, files_dict):\n",
    "    o = files_dict[pid]    \n",
    "    l = sorted(o, key=lambda x: x['slice_no']) \n",
    "    return tensor([o['embs_idx'] for o in l])\n",
    "\n",
    "def get_img_y(pid, files_dict):\n",
    "    o = files_dict[pid]    \n",
    "    l = sorted(o, key=lambda x: x['slice_no']) \n",
    "    img_y = [o['img_y'] for o in l]\n",
    "    img_y = tensor(img_y).float()\n",
    "    return img_y\n",
    "\n",
    "def get_exam_y(pid, files_dict):\n",
    "    \"\"\" 4 prediction heads\n",
    "    'POSITIVE','negative_exam_for_pe','indeterminate' - Sotfmax\n",
    "    \n",
    "    'rv_lv_ratio_gte_1','rv_lv_ratio_lt_1', 'NEITHER' - Softmax\n",
    "    \n",
    "    'leftsided_pe','rightsided_pe','central_pe' - Sigmoid\n",
    "    \n",
    "    'chronic_pe','acute_and_chronic_pe','NEITHER' - Sotfmax\n",
    "    \"\"\"\n",
    "    d = files_dict[pid][0]\n",
    "    exam_arr = list(d['exam_y'])\n",
    "\n",
    "    # add POSITIVE\n",
    "    is_pos = 0 if max(exam_arr[:2]) == 1 else 0\n",
    "    exam_arr = [is_pos] + exam_arr\n",
    "    \n",
    "    # add NEITHER for rv/lv\n",
    "    rvlv_neither = 1 if not is_pos else 0\n",
    "    exam_arr = exam_arr[:5] + [rvlv_neither] + exam_arr[5:]\n",
    "    \n",
    "    # add NEITHER for chronic or acute\n",
    "    chro_acc_neither = 1 if not is_pos else 0\n",
    "    exam_arr = exam_arr + [chro_acc_neither]\n",
    "\n",
    "    exam_y = tensor(exam_arr).float()\n",
    "    return exam_y\n",
    "    \n",
    "# before_batch: after collecting samples before collating\n",
    "targ_pad_idx = 666\n",
    "def SequenceBlock():       return  TransformBlock(type_tfms=[partial(get_x, files_dict=files_dict)], \n",
    "                                                  dl_type=SortedDL,\n",
    "                                                  dls_kwargs={'before_batch':\n",
    "                                                               [partial(pad_input, pad_idx=input_pad_idx),\n",
    "                                                                partial(pad_input, pad_idx=targ_pad_idx, pad_fields=1)]})\n",
    "def SequenceTargetBlock(): return TransformBlock(type_tfms=[partial(get_img_y, files_dict=files_dict)])\n",
    "def TargetBlock():         return TransformBlock(type_tfms=[partial(get_exam_y, files_dict=files_dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_img_y(all_pids[0], files_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_exam_y(all_pids[0], files_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict[all_pids[0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_embeddings = F.normalize(combined_embeddings, dim=0)\n",
    "# normalized_embeddings.isnan().sum()\n",
    "# normalized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert combined_embeddings.isnan().sum().item() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = default_device(1); device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWD_LSTM(Module):\n",
    "    \"AWD-LSTM inspired by https://arxiv.org/abs/1708.02182\"\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, emb_sz,n_hid, n_layers, hidden_p=0.2, input_p=0.6, weight_p=0.5, bidir=False):\n",
    "        store_attr('emb_sz,n_hid,n_layers')\n",
    "        self.bs = 1\n",
    "        self.n_dir = 2 if bidir else 1\n",
    "        \n",
    "        self.rnns = nn.ModuleList([self._one_rnn(emb_sz if l == 0 else n_hid, (n_hid)//self.n_dir, bidir, weight_p, l) for l in range(n_layers)])\n",
    "\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n",
    "        self.reset()\n",
    "\n",
    "    def forward(self, x, from_embeds=False):\n",
    "        \n",
    "        if from_embeds: inp = x\n",
    "        else: inp = combined_embeddings[x].to(device)\n",
    "        bs,sl = inp.shape[:2]\n",
    "        if bs!=self.bs: self._change_hidden(bs)\n",
    "\n",
    "        output = self.input_dp(inp)\n",
    "        new_hidden = []\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            output, new_h = rnn(output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            if l != self.n_layers - 1: output = hid_dp(output)\n",
    "        self.hidden = to_detach(new_hidden, cpu=False, gather=False)\n",
    "        return output\n",
    "\n",
    "    def _change_hidden(self, bs):\n",
    "        self.hidden = [self._change_one_hidden(l, bs) for l in range(self.n_layers)]\n",
    "        self.bs = bs\n",
    "\n",
    "    def _one_rnn(self, n_in, n_out, bidir, weight_p, l):\n",
    "        \"Return one of the inner rnn\"\n",
    "        rnn = nn.LSTM(n_in, n_out, 1, batch_first=True, bidirectional=bidir, bias=False)\n",
    "        return WeightDropout(rnn, weight_p)\n",
    "\n",
    "    def _one_hidden(self, l):\n",
    "        \"Return one hidden state\"\n",
    "        nh = (self.n_hid) // self.n_dir\n",
    "        return (one_param(self).new_zeros(self.n_dir, self.bs, nh), one_param(self).new_zeros(self.n_dir, self.bs, nh))\n",
    "\n",
    "    def _change_one_hidden(self, l, bs):\n",
    "        if self.bs < bs:\n",
    "            nh = (self.n_hid) // self.n_dir\n",
    "            return tuple(torch.cat([h, h.new_zeros(self.n_dir, bs-self.bs, nh)], dim=1) for h in self.hidden[l])\n",
    "        if self.bs > bs: return (self.hidden[l][0][:,:bs].contiguous(), self.hidden[l][1][:,:bs].contiguous())\n",
    "        return self.hidden[l]\n",
    "\n",
    "    def reset(self):\n",
    "        \"Reset the hidden states\"\n",
    "        [r.reset() for r in self.rnns if hasattr(r, 'reset')]\n",
    "        self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_width = 512\n",
    "layers = [lstm_width * 3] + [lstm_width] + [12]\n",
    "\n",
    "class MultiHeadedSoftmaxSequenceClassifier(Module):\n",
    "    \"dim: input sequence feature dim\"\n",
    "    def __init__(self, bptt=72, input_pad_idx=input_pad_idx, n_meta=1, dim=1024, nlayers=2, cls_ps=[0.4, 0.1], **awd_kwargs):\n",
    "        \n",
    "        store_attr('input_pad_idx')\n",
    "        self.awd_lstm = AWD_LSTM(dim+n_meta, lstm_width, nlayers, bidir=True, **awd_kwargs)\n",
    "#         self.awd_lstm = AWD_QRNN(dim+n_meta, 512, 2, bidir=True)\n",
    "        self.encoder = SentenceEncoder(bptt=bptt, module=self.awd_lstm, pad_idx=input_pad_idx)\n",
    "        \n",
    "        # image level preds\n",
    "        self.seq_head = LinearDecoder(1, lstm_width, bias=True)\n",
    " \n",
    "        # exam level preds\n",
    "        self.exam_head = PoolingLinearClassifier(layers, ps=cls_ps, bptt=bptt)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, mask = self.encoder(x) \n",
    "       \n",
    "        # img level out\n",
    "        seq_cls_out,_,_ = self.seq_head(out)\n",
    "        seq_cls_out = seq_cls_out.squeeze(-1)\n",
    "              \n",
    "        # exam level out\n",
    "        exam_out,_,_ = self.exam_head((out,mask))\n",
    "        posneg_out, rvlv_out, lrc_out, chroacute_out = (exam_out[:,:3], \n",
    "                                                        exam_out[:,3:6], \n",
    "                                                        exam_out[:,6:9], \n",
    "                                                        exam_out[:,9:])\n",
    "\n",
    "        return (seq_cls_out, posneg_out, rvlv_out, lrc_out, chroacute_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLossSoftmax(Module):\n",
    "    \n",
    "    def __init__(self, targ_pad_idx=666):\n",
    "        store_attr(\"targ_pad_idx\")\n",
    "\n",
    "    def forward(self, inp, yb0, yb1):\n",
    "\n",
    "        seq_cls_out, posneg_out, rvlv_out, lrc_out, chroacute_out = inp\n",
    "\n",
    "        #             'negative_exam_for_pe',\n",
    "        #             'indeterminate',\n",
    "\n",
    "        #             'rv_lv_ratio_gte_1',\n",
    "        #             'rv_lv_ratio_lt_1',\n",
    "        #     # none\n",
    "\n",
    "        #             'leftsided_pe',\n",
    "        #             'rightsided_pe',\n",
    "        #             'central_pe',\n",
    "\n",
    "        #             'chronic_pe',\n",
    "        #             'acute_and_chronic_pe', \n",
    "        image_target_weight = 0.07361963\n",
    "        exam_target_weights = tensor([0.0736196319, 0.09202453988, \n",
    "                                      0.2346625767, 0.0782208589,\n",
    "                                      0.06257668712, 0.06257668712, 0.1877300613,\n",
    "                                      0.1042944785, 0.1042944785]).to(yb1.device)\n",
    "        # img loss\n",
    "        mask = yb0 != self.targ_pad_idx \n",
    "\n",
    "        img_loss, qs = 0, 0        \n",
    "        for _m,_y,_p in zip(mask, yb0, seq_cls_out):\n",
    "            qi = _y[_m].mean()\n",
    "            qs += image_target_weight*qi*sum(_m)\n",
    "            img_loss += image_target_weight*qi*(F.binary_cross_entropy_with_logits(_p[_m], _y[_m], reduction='sum'))\n",
    "\n",
    "        # exam loss\n",
    "        # 'POSITIVE','negative_exam_for_pe','indeterminate'\n",
    "        posneg_out = posneg_out.softmax(1)\n",
    "        posneg_losses = F.binary_cross_entropy(posneg_out, yb1[:,:3], reduction='none')[:, 1:]\n",
    "        tot_posneg_losses = (posneg_losses*(exam_target_weights[:2].unsqueeze(0))).sum()\n",
    "        tot_posneg_wgts = len(posneg_losses)*(tensor(exam_target_weights[:2]).sum())\n",
    "\n",
    "        # 'rv_lv_ratio_gte_1','rv_lv_ratio_lt_1', 'NEITHER'\n",
    "        rvlv_out = rvlv_out.softmax(1)\n",
    "        rvlv_losses = F.binary_cross_entropy(rvlv_out, yb1[:,3:6], reduction='none')[:, :2]\n",
    "        tot_rvlv_losses = (rvlv_losses*(exam_target_weights[2:4].unsqueeze(0))).sum()\n",
    "        tot_rvlv_wgts = len(rvlv_losses)*(tensor(exam_target_weights[2:4]).sum())\n",
    "\n",
    "        # 'leftsided_pe','rightsided_pe','central_pe'\n",
    "        lrc_losses = F.binary_cross_entropy_with_logits(lrc_out, yb1[:,6:9], reduction='none')\n",
    "        tot_lrc_losses = (lrc_losses*(exam_target_weights[4:7].unsqueeze(0))).sum()\n",
    "        tot_lrc_wgts = len(lrc_losses)*(tensor(exam_target_weights[6:9]).sum())\n",
    "\n",
    "        # 'chronic_pe','acute_and_chronic_pe','NEITHER'\n",
    "        chroacute_out = chroacute_out.softmax(1)\n",
    "        chroacute_losses = F.binary_cross_entropy(chroacute_out, yb1[:,9:], reduction='none')[:, :2]\n",
    "        tot_chroacute_losses = (chroacute_losses*(exam_target_weights[7:].unsqueeze(0))).sum()\n",
    "        tot_chroacute_wgts = len(chroacute_losses)*(tensor(exam_target_weights[7:]).sum())\n",
    "\n",
    "        tot_exam_loss = (tot_posneg_losses+tot_rvlv_losses+tot_lrc_losses+tot_chroacute_losses)\n",
    "        tot_exam_wgts = (tot_posneg_wgts+tot_rvlv_wgts+tot_lrc_wgts+tot_chroacute_wgts)\n",
    "\n",
    "\n",
    "\n",
    "        return (tot_exam_loss+img_loss)/(qs+tot_exam_wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLossSoftmax(Module):\n",
    "    \n",
    "    def __init__(self, targ_pad_idx=666):\n",
    "        store_attr(\"targ_pad_idx\")\n",
    "\n",
    "    def forward(self, inp, yb0, yb1):\n",
    "\n",
    "        seq_cls_out, posneg_out, rvlv_out, lrc_out, chroacute_out = inp\n",
    "\n",
    "        #             'negative_exam_for_pe',\n",
    "        #             'indeterminate',\n",
    "\n",
    "        #             'rv_lv_ratio_gte_1',\n",
    "        #             'rv_lv_ratio_lt_1',\n",
    "        #     # none\n",
    "\n",
    "        #             'leftsided_pe',\n",
    "        #             'rightsided_pe',\n",
    "        #             'central_pe',\n",
    "\n",
    "        #             'chronic_pe',\n",
    "        #             'acute_and_chronic_pe', \n",
    "        image_target_weight = 0.07361963\n",
    "        exam_target_weights = tensor([0.0736196319, 0.09202453988, \n",
    "                                      0.2346625767, 0.0782208589,\n",
    "                                      0.06257668712, 0.06257668712, 0.1877300613,\n",
    "                                      0.1042944785, 0.1042944785]).to(yb1.device)\n",
    "\n",
    "        # img loss\n",
    "        mask = yb0 != self.targ_pad_idx \n",
    "\n",
    "        img_loss, qs = 0, 0        \n",
    "        for _m,_y,_p in zip(mask, yb0, seq_cls_out):\n",
    "            qi = _y[_m].mean()\n",
    "            qs += image_target_weight*qi*sum(_m)\n",
    "            img_loss += image_target_weight*qi*(F.binary_cross_entropy_with_logits(_p[_m], _y[_m], reduction='sum'))\n",
    "        return (img_loss)/(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExamLossSoftmax(Module):\n",
    "    \n",
    "    def __init__(self, targ_pad_idx=666):\n",
    "        store_attr(\"targ_pad_idx\")\n",
    "\n",
    "    def forward(self, inp, yb0, yb1):\n",
    "\n",
    "        seq_cls_out, posneg_out, rvlv_out, lrc_out, chroacute_out = inp\n",
    "\n",
    "        #             'negative_exam_for_pe',\n",
    "        #             'indeterminate',\n",
    "\n",
    "        #             'rv_lv_ratio_gte_1',\n",
    "        #             'rv_lv_ratio_lt_1',\n",
    "        #     # none\n",
    "\n",
    "        #             'leftsided_pe',\n",
    "        #             'rightsided_pe',\n",
    "        #             'central_pe',\n",
    "\n",
    "        #             'chronic_pe',\n",
    "        #             'acute_and_chronic_pe', \n",
    "        image_target_weight = 0.07361963\n",
    "        exam_target_weights = tensor([0.0736196319, 0.09202453988, \n",
    "                                      0.2346625767, 0.0782208589,\n",
    "                                      0.06257668712, 0.06257668712, 0.1877300613,\n",
    "                                      0.1042944785, 0.1042944785]).to(yb1.device)\n",
    "\n",
    "\n",
    "        # exam loss\n",
    "        # 'POSITIVE','negative_exam_for_pe','indeterminate'\n",
    "        posneg_out = posneg_out.softmax(1)\n",
    "        posneg_losses = F.binary_cross_entropy(posneg_out, yb1[:,:3], reduction='none')[:, 1:]\n",
    "        tot_posneg_losses = (posneg_losses*(exam_target_weights[:2].unsqueeze(0))).sum()\n",
    "        tot_posneg_wgts = len(posneg_losses)*(tensor(exam_target_weights[:2]).sum())\n",
    "\n",
    "        # 'rv_lv_ratio_gte_1','rv_lv_ratio_lt_1', 'NEITHER'\n",
    "        rvlv_out = rvlv_out.softmax(1)\n",
    "        rvlv_losses = F.binary_cross_entropy(rvlv_out, yb1[:,3:6], reduction='none')[:, :2]\n",
    "        tot_rvlv_losses = (rvlv_losses*(exam_target_weights[2:4].unsqueeze(0))).sum()\n",
    "        tot_rvlv_wgts = len(rvlv_losses)*(tensor(exam_target_weights[2:4]).sum())\n",
    "\n",
    "        # 'leftsided_pe','rightsided_pe','central_pe'\n",
    "        lrc_losses = F.binary_cross_entropy_with_logits(lrc_out, yb1[:,6:9], reduction='none')\n",
    "        tot_lrc_losses = (lrc_losses*(exam_target_weights[4:7].unsqueeze(0))).sum()\n",
    "        tot_lrc_wgts = len(lrc_losses)*(tensor(exam_target_weights[6:9]).sum())\n",
    "\n",
    "        # 'chronic_pe','acute_and_chronic_pe','NEITHER'\n",
    "        chroacute_out = chroacute_out.softmax(1)\n",
    "        chroacute_losses = F.binary_cross_entropy(chroacute_out, yb1[:,9:], reduction='none')[:, :2]\n",
    "        tot_chroacute_losses = (chroacute_losses*(exam_target_weights[7:].unsqueeze(0))).sum()\n",
    "        tot_chroacute_wgts = len(chroacute_losses)*(tensor(exam_target_weights[7:]).sum())\n",
    "\n",
    "        tot_exam_loss = (tot_posneg_losses+tot_rvlv_losses+tot_lrc_losses+tot_chroacute_losses)\n",
    "        tot_exam_wgts = (tot_posneg_wgts+tot_rvlv_wgts+tot_lrc_wgts+tot_chroacute_wgts)\n",
    "\n",
    "\n",
    "\n",
    "        return (tot_exam_loss)/(tot_exam_wgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cv = True\n",
    "FOLD = fold\n",
    "\n",
    "if do_cv: \n",
    "    valid_pids = pd.read_pickle(datapath/f'cv_pids/pids_fold{FOLD}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBlock(blocks=(SequenceBlock,SequenceTargetBlock,TargetBlock), \n",
    "                 n_inp=1, \n",
    "                 splitter=FuncSplitter(lambda o: True if o in valid_pids else False)\n",
    "                )\n",
    "dls = data.dataloaders(all_pids, bs=128)\n",
    "model = SequentialRNN(MultiHeadedSoftmaxSequenceClassifier(bptt=256, n_meta=2, dim=1024, nlayers=2)) # dim = 1536 for effnet 1024 for xresnet\n",
    "loss_func = MultiLossSoftmax()\n",
    "learner = Learner(dls, model, loss_func=loss_func, metrics=[ImageLossSoftmax(), ExamLossSoftmax()],\n",
    "                  cbs=[ModelResetter(),TerminateOnNaNCallback(), \n",
    "                      SaveModelCallback(fname=f\"nometa_sequence_softmax_with_preds_fulldata_fold{fold}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_flat_cos(20, lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get OOF Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pid(pid):\n",
    "    return pid\n",
    "\n",
    "def get_x(pid, files_dict):\n",
    "    o = files_dict[pid]    \n",
    "    l = sorted(o, key=lambda x: x['slice_no']) \n",
    "    return tensor([o['embs_idx'] for o in l])\n",
    "\n",
    "def get_img_y(pid, files_dict):\n",
    "    o = files_dict[pid]    \n",
    "    l = sorted(o, key=lambda x: x['slice_no']) \n",
    "    img_y = [o['img_y'] for o in l]\n",
    "    img_y = tensor(img_y).float()\n",
    "    return img_y\n",
    "\n",
    "def get_exam_y(pid, files_dict):\n",
    "    \"\"\" 4 prediction heads\n",
    "    'POSITIVE','negative_exam_for_pe','indeterminate' - Sotfmax\n",
    "    \n",
    "    'rv_lv_ratio_gte_1','rv_lv_ratio_lt_1', 'NEITHER' - Softmax\n",
    "    \n",
    "    'leftsided_pe','rightsided_pe','central_pe' - Sigmoid\n",
    "    \n",
    "    'chronic_pe','acute_and_chronic_pe','NEITHER' - Sotfmax\n",
    "    \"\"\"\n",
    "    d = files_dict[pid][0]\n",
    "    exam_arr = list(d['exam_y'])\n",
    "\n",
    "    # add POSITIVE\n",
    "    is_pos = 0 if max(exam_arr[:2]) == 1 else 0\n",
    "    exam_arr = [is_pos] + exam_arr\n",
    "    \n",
    "    # add NEITHER for rv/lv\n",
    "    rvlv_neither = 1 if not is_pos else 0\n",
    "    exam_arr = exam_arr[:5] + [rvlv_neither] + exam_arr[5:]\n",
    "    \n",
    "    # add NEITHER for chronic or acute\n",
    "    chro_acc_neither = 1 if not is_pos else 0\n",
    "    exam_arr = exam_arr + [chro_acc_neither]\n",
    "\n",
    "    exam_y = tensor(exam_arr).float()\n",
    "    return exam_y\n",
    "    \n",
    "# before_batch: after collecting samples before collating\n",
    "targ_pad_idx = 666\n",
    "def SequenceBlock():       return  TransformBlock(type_tfms=[partial(get_x, files_dict=files_dict)], \n",
    "                                                  dl_type=SortedDL,\n",
    "                                                  dls_kwargs={'before_batch':\n",
    "                                                               [partial(pad_input, pad_idx=input_pad_idx),\n",
    "                                                                partial(pad_input, pad_idx=targ_pad_idx, pad_fields=1)]})\n",
    "def PidBlock(): return TransformBlock(type_tfms=[get_pid])\n",
    "def SequenceTargetBlock(): return TransformBlock(type_tfms=[partial(get_img_y, files_dict=files_dict)])\n",
    "def TargetBlock():         return TransformBlock(type_tfms=[partial(get_exam_y, files_dict=files_dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBlock(blocks=(SequenceBlock,SequenceTargetBlock,TargetBlock), \n",
    "                 n_inp=1, \n",
    "                 splitter=FuncSplitter(lambda o: True if o in valid_pids else False)\n",
    "                )\n",
    "dls = data.dataloaders(all_pids, bs=128)\n",
    "model = SequentialRNN(MultiHeadedSoftmaxSequenceClassifier(bptt=256, n_meta=2, dim=1024, nlayers=2)) # dim = 1536 for effnet 1024 for xresnet\n",
    "loss_func = MultiLossSoftmax()\n",
    "learner = Learner(dls, model, loss_func=loss_func, metrics=[ImageLossSoftmax(), ExamLossSoftmax()],\n",
    "                  cbs=[ModelResetter(),TerminateOnNaNCallback(), \n",
    "                      SaveModelCallback(fname=f\"nometa_sequence_softmax_with_preds_fulldata_fold{fold}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load(f\"nometa_sequence_softmax_with_preds_fulldata_fold{fold}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.eval().to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learner.dls.test_dl(all_pids, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_pids = []\n",
    "seq_img_preds = []\n",
    "seq_img_targs = []\n",
    "seq_exam_preds = []\n",
    "seq_exam_targs = []\n",
    "with torch.no_grad():\n",
    "    for xb,yb0,yb1,pids in progress_bar(test_dl):\n",
    "        img_pred, exam_pred = to_detach(learner.model(xb))\n",
    "        seq_img_preds.append(img_pred)\n",
    "        seq_img_targs.append(yb0)\n",
    "        seq_exam_preds.append(exam_pred)\n",
    "        seq_exam_targs.append(yb1)\n",
    "        seq_pids.append(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_datapath = datapath/'final_lstm_stacking'\n",
    "if not stacking_datapath.exists(): stacking_datapath.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = f\"xresnet_softmax_FOLD{FOLD}\"\n",
    "stacking_folder = stacking_datapath/subfolder\n",
    "if not stacking_folder.exists(): stacking_folder.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq_pids), len(seq_img_preds), len(seq_img_targs), len(seq_exam_preds), len(seq_exam_targs), len(valid_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq_pids, stacking_folder/'seq_pids.pth')\n",
    "torch.save(seq_img_preds, stacking_folder/'seq_img_preds.pth')\n",
    "torch.save(seq_img_targs, stacking_folder/'seq_img_targs.pth')\n",
    "torch.save(seq_exam_preds, stacking_folder/'seq_exam_preds.pth')\n",
    "torch.save(seq_exam_targs, stacking_folder/'seq_exam_targs.pth')\n",
    "torch.save(valid_pids, stacking_folder/'valid_pids.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
